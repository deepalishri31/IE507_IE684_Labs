{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "21i190006_Lab03_Ex1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVE0Xoa0Q5wE"
      },
      "source": [
        "$\\Large\\textbf{Lab 3.}$ $\\large\\textbf{Exercise 1.}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVkab74DJsRL"
      },
      "source": [
        "In the last lab, when we tried to solve certain problems of the form $\\min_{\\mathbf{x} \\in {\\mathbb{R}}^n} f(\\mathbf{x})$ using gradient descent algorithm, we noticed that the algorithm needed a large number of iterations to find the minimizer. Today we will discuss some remedy measures for this issue.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-Meohokl4xP"
      },
      "source": [
        "Consider the problem $\\min_{\\mathbf{x}} f(\\mathbf{x}) = 1500x_1^2 + 4x_1 x_2 +  x_2^2$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvWjvAgnXxS3"
      },
      "source": [
        "Note that the function $f(\\mathbf{x})$ is twice continuously differentiable. First let us investigate the Hessian $\\nabla^2 f(\\mathbf{x})$ of the function. \n",
        "\n",
        "Note that the Hessian $\\nabla^2 f(\\mathbf{x})$ of the function $f(\\mathbf{x})$ is positive definite. \n",
        "\n",
        "Due to the positive definite nature of the Hessian, we shall find the condition number of the Hessian given by $\\kappa\\left (\\nabla^2 f(\\mathbf{x}) \\right ) = \\frac{\\lambda_{\\max} \\left (\\nabla^2 f(\\mathbf{x}) \\right )}{\\lambda_{\\min} \\left (\\nabla^2 f(\\mathbf{x}) \\right )}$, where $\\lambda_{\\max}(\\mathbf{A})$ denotes the maximum eigen value of matrix $\\mathbf{A}$ and $\\lambda_{\\min}(\\mathbf{A})$ denotes the minimum eigen value of matrix $\\mathbf{A}$.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLfdgrmxANif"
      },
      "source": [
        "Ques 2:\n",
        "\n",
        " Write code to find the Hessian matrix of the function $f(\\mathbf{x}) = 1500x_1^2 + 4x_1 x_2 +  x_2^2$ and its condition number. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72qwiJ0CDtOX"
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "#method to find Hessian matrix: Complete the code\n",
        "def evalh(x): \n",
        "  assert type(x) is np.ndarray \n",
        "  assert len(x) == 2\n",
        "  H = [[3000,4],[4,2]]\n",
        "  return H\n",
        "\n",
        "\n",
        "#method to find the condition number of any square matrix: : Complete the code\n",
        "def find_condition_number(A):\n",
        "  assert type(A) is np.ndarray\n",
        "  assert A.shape[0] == A.shape[1]\n",
        "  ev,evs = np.linalg.eig(A)\n",
        "  return max(ev)/min(ev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7ivDCuJRP9b"
      },
      "source": [
        "The condition number of the Hessian plays a major role in the progress of the iterates of gradient descent towards the optimal solution point. Typically a large value of the condition number indicates that the problem is $\\textbf{ill-conditioned}$ and hence leads to slow progress of the iterates towards the optimal solution point. Now we shall discuss a method which would help in better $\\textbf{conditioning}$ of the problem and hence would help in speeding up the progress of the iterates towards the optimal solution point. \n",
        "\n",
        "Let us first illustrate an equivalent transformation of the problem $\\min_{\\mathbf{x} \\in {\\mathbb{R}}^n} f(\\mathbf{x})$. Consider the transformation $\\mathbf{x}=\\mathbf{My}$ where $\\mathbf{M}\\in {\\mathbb{R}}^{n \\times n}$ is an invertible matrix and $\\mathbf{y} \\in {\\mathbb{R}}^n$ and consider the equivalent problem $\\min_{\\mathbf{y} \\in {\\mathbb{R}}^n} g(\\mathbf{y}) \\equiv \\min_{\\mathbf{y} \\in {\\mathbb{R}}^n} f(\\mathbf{My})$. \n",
        "\n",
        "$\\textbf{Check:}$ Why are the two problems $\\min_{\\mathbf{x} \\in {\\mathbb{R}}^n} f(\\mathbf{x})$ and $\\min_{\\mathbf{y} \\in {\\mathbb{R}}^n} g(\\mathbf{y})$  equivalent? \n",
        "\n",
        "Note that the gradient $\\nabla_{\\mathbf{y}} g(\\mathbf{y}) = \\mathbf{M}^\\top \\nabla_{\\mathbf{x}} f(\\mathbf{x})$ and the Hessian is $\\nabla^2_{\\mathbf{y}} g(\\mathbf{y}) = \\mathbf{M}^\\top \\nabla^2_{\\mathbf{x}} f(\\mathbf{x}) \\mathbf{M}$. \n",
        "\n",
        "Hence the gradient descent update to solve $\\min_{\\mathbf{y} \\in {\\mathbb{R}}^n} g(\\mathbf{y})$ becomes: \n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "{\\mathbf{y}}^{k+1} &= {\\mathbf{y}}^{k} - \\eta \\nabla_{\\mathbf{y}} g({\\mathbf{y}}^{k}) \\\\\n",
        "\\end{align}\n",
        "\n",
        "Pre-multiplying by $\\mathbf{M}$, we have:\n",
        "\\begin{align}\n",
        "{\\mathbf{M}\\mathbf{y}}^{k+1} &= {\\mathbf{M}\\mathbf{y}}^{k} -  \\eta \\mathbf{M} \\nabla_{\\mathbf{y}} g({\\mathbf{y}}^{k})  \\\\\n",
        "\\implies \\mathbf{x}^{k+1} &= \\mathbf{x}^{k} - \\eta \\mathbf{MM}^\\top \\nabla_{\\mathbf{x}} f({\\mathbf{x}}^{k}) \n",
        "\\end{align}\n",
        "\n",
        "\n",
        "Letting $\\mathbf{D} = \\mathbf{MM}^\\top$, we see that the update is of the form:\n",
        "\\begin{align}\n",
        "\\mathbf{x}^{k+1} &= \\mathbf{x}^{k} - \\eta \\mathbf{D} \\nabla f({\\mathbf{x}}^{k}) \n",
        "\\end{align}\n",
        "\n",
        "Note that the matrix $\\mathbf{D}$ is symmetric and positive definite and hence can be written as $\\mathbf{D} = \\mathbf{B}^2$, where $\\mathbf{B}$ is also symmetric and positive definite. Denoting $\\mathbf{B}= \\mathbf{D}^{\\frac{1}{2}}$, we see that a useful choice for the matrix $\\mathbf{M}$ is $\\mathbf{M} = \\mathbf{B} = \\mathbf{D}^{\\frac{1}{2}}$. \n",
        "\n",
        "The matrix $\\mathbf{D}$ is called a $\\textbf{scaling}$ matrix and helps in scaling the Hessian. We will consider $\\mathbf{D}$ to be a diagonal matrix. Thus it would be useful to find a suitable candidate of the scaling matrix at each iteration which could help in significant progress of the iterates towards the optimal solution. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgHGXcTYNXuw"
      },
      "source": [
        "This discussion leads to the following algorithm:\n",
        "\\begin{align}\n",
        "& \\textbf{Input:} \\text{ Starting point $x^0$, Stopping tolerance $\\tau$}  \\\\\n",
        "& \\textbf{Initialize } k=0 \\\\ \n",
        "& \\mathbf{p}^k =-\\nabla f(\\mathbf{x}^k) \\\\ \n",
        "&\\textbf{While } \\| \\mathbf{p}^k \\|_2 > \\tau \\text{ do:}  \\\\   \n",
        "&\\quad \\quad \\text{ Choose a suitable scaling matrix }\\mathbf{D}^k. \\\\ \n",
        "&\\quad \\quad \\eta^k = \\arg\\min_{\\eta\\geq 0} f(\\mathbf{x}^k + \\eta  \\mathbf{D}^k \\mathbf{p}^k) = \\arg\\min_{\\eta\\geq 0} f(\\mathbf{x}^k - \\eta  \\mathbf{D}^k \\nabla f(\\mathbf{x}^k)) \\\\\n",
        "&\\quad \\quad \\mathbf{x}^{k+1} = \\mathbf{x}^k + \\eta^k \\mathbf{D}^k \\mathbf{p}^k = \\mathbf{x}^k - \\eta^k  \\mathbf{D}^k \\nabla f(\\mathbf{x}^k)  \\\\ \n",
        "&\\quad \\quad k = {k+1} \\\\ \n",
        "&\\textbf{End While} \\\\\n",
        "&\\textbf{Output: } \\mathbf{x}^k\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XvbzQ5LeJ_N"
      },
      "source": [
        "Note that the update step in the modified gradient descent scheme uses a scaled gradient. Thus it becomes important to set up some criteria for choosing the $\\mathbf{D}^k$ matrix in every iteration. In this exercise, we will assume $\\mathbf{D}^k$ to be a diagonal matrix. The following questions will help in designing a suitable $\\mathbf{D}^k$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC5h9vGOfLcr"
      },
      "source": [
        "#Ques 4:\n",
        " Based on our discussion on condition number and the derivation of the gradient descent scheme with scaling, can you identify and write down the matrix $\\mathbf{Q}$ whose condition number needs to be analyzed in the new gradient scheme with scaling? "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Condition number of matrix $\\mathbf{Q}$ needs to be analyzed in new gradient scheme with scaling  with $\\mathbf{D}^k$ \\\\\n",
        "\n",
        "$\\mathbf{Q}$  = $(\\mathbf{D}^k)^{\\frac{1}{2}} \\mathbf{H}^k (\\mathbf{D}^k)^{\\frac{1}{2}}$\n",
        "\n",
        "Where, $\\mathbf{H}^k = (\\nabla^2f(\\mathbf{x})) $ is the hessian of a function at each iteration.\n",
        "\n",
        "$\\mathbf{D}^k$ is shown in the question 5 below.\n",
        "\n",
        "Condition Number of matrix $\\mathbf{Q}$ in the Gradient Descent Scheme has reduced to nearly $1$ due to such choice of matrix $\\mathbf{Q}$ so that our gradient descent  algorithm with scaling becomes more accurate and fast."
      ],
      "metadata": {
        "id": "6mE4Muf7EkoB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrbWd2XigB2N"
      },
      "source": [
        "#Ques 5:\n",
        " Based on the matrix $\\mathbf{Q}$, can you come up with a useful choice for $\\mathbf{D}^k$ (assuming $\\mathbf{D}^k$ to be diagonal)? \\\\\n",
        "#Answer: \n",
        "Diagonal approximation to the Hessian matrix $\\nabla^2f( \\mathbf{x})$, i.e., the diagonal matrix $\\mathbf{D}^k$ that has the inverse second partial derivatives $\\Big(\\frac{\\partial^2f(\\mathbf{x_k})}{(\\partial x_i)^2}\\Big)^{-1}$ along the diagonal. This improves the performance of the gradient method dramatically, by providing automatic scaling of the units in which the components $x_i$ of $\\mathbf{x}$ are measured. Because of such choice of $\\mathbf{D}^k$, the condition number of $\\mathbf{Q}$ is improving and becoming so close to $1$ so that our gradient descent scheme is converging so quickly. Here, product with inverse of diagonal elements of hessian matrix with hessian matrix is causing the improvements in $\\mathbf{Q}$ by becoming so close to condition number of identity matrix. This is so helpful in fasterness of the algorithm.\n",
        "\n",
        "$\\therefore \\mathbf{D^k} =\n",
        "\\begin{bmatrix}\n",
        "  \\frac{1}{2000} & 0 \\\\ 0 & \\frac{1}{2}\n",
        "\\end{bmatrix}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDNH0zgxgaPR"
      },
      "source": [
        "Write code to find the matrix $\\mathbf{D}^k$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJq7tIgIRroP"
      },
      "source": [
        "#The method defines a way to construct D_k matrix used in scaling the gradient in the modified gradient descent scheme\n",
        "def compute_D_k(x):\n",
        "  assert type(x) is np.ndarray\n",
        "  assert len(x) == 2\n",
        "  #compute and return D_k\n",
        "  return np.array([[1/3000,0],[0,1/2]])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZjX2IwOR8_X"
      },
      "source": [
        "#Now we will define a Python function which will compute and return the objective function value \n",
        "def evalf(x):  \n",
        "  #Input: x is a numpy array of size 2 \n",
        "  assert type(x) is np.ndarray and len(x) == 2 #do not allow arbitrary arguments \n",
        "  #after checking if the argument is valid, we can compute the objective function value\n",
        "  #compute the function value and return it \n",
        "  return 1500*x[0]**2 + 4*x[0]*x[1] + x[1]**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6klpwtDra_I8"
      },
      "source": [
        "#Now we will define a Python function which will compute and return the gradient value as a numpy array \n",
        "def evalg(x):  \n",
        "  #Input: x is a numpy array of size 2 \n",
        "  assert type(x) is np.ndarray and len(x) == 2 #do not allow arbitrary arguments \n",
        "  #after checking if the argument is valid, we can compute the gradient value\n",
        "  #compute the gradient value and return it \n",
        "  return np.array([(3000*x[0]+4*x[1]),(4*x[0]+2*x[1])])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3blM08V0HOl"
      },
      "source": [
        "#Complete the module to compute the steplength by using the closed-form expression\n",
        "def compute_steplength_exact(gradf, A): #add appropriate arguments to the function \n",
        "  assert type(gradf) is np.ndarray and len(gradf) == 2 \n",
        "  assert type(A) is np.ndarray and A.shape[0] == 2 and  A.shape[1] == 2 #allow only a 2x2 array\n",
        "  step_length = np.dot(gradf,gradf)/np.dot(gradf,np.matmul(2*A,gradf))\n",
        "  return step_length\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGunDYy6Q21S"
      },
      "source": [
        "#Complete the module to compute the steplength by using the closed-form expression\n",
        "def compute_steplength_backtracking(x, gradf, alpha_start, rho, gamma): #add appropriate arguments to the function \n",
        "  assert type(x) is np.ndarray and len(gradf) == 2 \n",
        "  assert type(gradf) is np.ndarray and len(gradf) == 2 \n",
        "  assert type(alpha_start) is float and alpha_start>=0. \n",
        "  assert type(rho) is float and rho>=0.\n",
        "  assert type(gamma) is float and gamma>=0. \n",
        "  alpha = alpha_start\n",
        "  p=-evalg(x)\n",
        "  #implement the backtracking line search\n",
        "  while evalf(x+alpha*p)>evalf(x)+gamma*alpha*np.dot(evalg(x),p):\n",
        "    alpha = rho*alpha\n",
        "\n",
        "  #print('final step length:',alpha)\n",
        "  return alpha\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqjdHM3eaHYf"
      },
      "source": [
        "def compute_steplength_backtracking_scaled_direction(x, gradf, direction, alpha_start, rho, gamma): #add appropriate arguments to the function \n",
        "  assert type(x) is np.ndarray and len(gradf) == 2 \n",
        "  assert type(gradf) is np.ndarray and len(gradf) == 2 \n",
        "  assert type(direction) is np.ndarray and len(direction) == 2 \n",
        "  assert type(alpha_start) is float and alpha_start>=0. \n",
        "  assert type(rho) is float and rho>=0.\n",
        "  assert type(gamma) is float and gamma>=0.\n",
        "  p=-gradf\n",
        "  alpha=alpha_start\n",
        "  D_k=compute_D_k(x)\n",
        "  \n",
        "  while evalf(x+alpha*np.matmul(D_k,p))>evalf(x)+gamma*alpha*np.matmul(np.matrix.transpose(gradf),np.matmul(D_k,p)):\n",
        "    alpha = rho*alpha\n",
        "\n",
        "  #print('final step length:',alpha)\n",
        "  return alpha"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvLRu5s635ph"
      },
      "source": [
        "#line search type \n",
        "EXACT_LINE_SEARCH = 1\n",
        "BACKTRACKING_LINE_SEARCH = 2\n",
        "CONSTANT_STEP_LENGTH = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdYW5nldqZU-"
      },
      "source": [
        "#complete the code for gradient descent to find the minimizer\n",
        "def find_minimizer_gd(start_x, tol, line_search_type,*args):\n",
        "  #Input: start_x is a numpy array of size 2, tol denotes the tolerance and is a positive float value\n",
        "  assert type(start_x) is np.ndarray and len(start_x) == 2 #do not allow arbitrary arguments \n",
        "  assert type(tol) is float and tol>=0 \n",
        "  A = np.array([[1500, 2],[2,1]])\n",
        "  x = start_x\n",
        "  g_x = evalg(x)\n",
        "\n",
        "  #initialization for backtracking line search\n",
        "  if(line_search_type == BACKTRACKING_LINE_SEARCH):\n",
        "    alpha_start = args[0]\n",
        "    rho = args[1]\n",
        "    gamma = args[2]\n",
        "    #print('Params for Backtracking LS: alpha start:', alpha_start, 'rho:', rho,' gamma:', gamma)\n",
        "\n",
        "  k = 0\n",
        "  #print('iter:',k, ' x:', x, ' f(x):', evalf(x), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "\n",
        "  while (np.linalg.norm(g_x) > tol): #continue as long as the norm of gradient is not close to zero upto a tolerance tol\n",
        "  \n",
        "    if line_search_type == EXACT_LINE_SEARCH:\n",
        "      step_length = compute_steplength_exact(g_x, A) #call the new function you wrote to compute the steplength\n",
        "      #raise ValueError('EXACT LINE SEARCH NOT YET IMPLEMENTED')\n",
        "    elif line_search_type == BACKTRACKING_LINE_SEARCH:\n",
        "      step_length = compute_steplength_backtracking(x,g_x, alpha_start,rho, gamma) #call the new function you wrote to compute the steplength\n",
        "      #raise ValueError('BACKTRACKING LINE SEARCH NOT YET IMPLEMENTED')\n",
        "    elif line_search_type == CONSTANT_STEP_LENGTH: #do a gradient descent with constant step length\n",
        "      step_length = 0.1\n",
        "    else:  \n",
        "      raise ValueError('Line search type unknown. Please check!')\n",
        "    \n",
        "    #implement the gradient descent steps here   \n",
        "    x = np.subtract(x, np.multiply(step_length,g_x)) #update x = x - step_length*g_x\n",
        "    k += 1 #increment iteration\n",
        "    g_x = evalg(x) #compute gradient at new point\n",
        "\n",
        "    #print('iter:',k, ' x:', x, ' f(x):', evalf(x), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "  return x , k , evalf(x) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SCJdqivdpxx"
      },
      "source": [
        "#complete the code for gradient descent with scaling to find the minimizer\n",
        "\n",
        "def find_minimizer_gdscaling(start_x, tol, line_search_type,*args):\n",
        "  #Input: start_x is a numpy array of size 2, tol denotes the tolerance and is a positive float value\n",
        "  assert type(start_x) is np.ndarray and len(start_x) == 2 #do not allow arbitrary arguments \n",
        "  assert type(tol) is float and tol>=0 \n",
        "  A = np.array([[1500, 2],[2,1]])\n",
        "  x = start_x\n",
        "  g_x = evalg(x)\n",
        "  D_k=compute_D_k(x)\n",
        "\n",
        "\n",
        "  #initialization for backtracking line search\n",
        "  if(line_search_type == BACKTRACKING_LINE_SEARCH):\n",
        "    alpha_start = args[0]\n",
        "    rho = args[1]\n",
        "    gamma = args[2]\n",
        "    #print('Params for Backtracking LS: alpha start:', alpha_start, 'rho:', rho,' gamma:', gamma)\n",
        "\n",
        "  k = 0\n",
        "  #print('iter:',k, ' x:', x, ' f(x):', evalf(x), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "\n",
        "  while (np.linalg.norm(g_x) > tol): #continue as long as the norm of gradient is not close to zero upto a tolerance tol\n",
        "  \n",
        "    if line_search_type == EXACT_LINE_SEARCH:\n",
        "      step_length = compute_steplength_exact(g_x, A) #call the new function you wrote to compute the steplength\n",
        "      #raise ValueError('EXACT LINE SEARCH NOT YET IMPLEMENTED')\n",
        "    elif line_search_type == BACKTRACKING_LINE_SEARCH:\n",
        "      step_length = compute_steplength_backtracking(x,g_x, alpha_start,rho, gamma) #call the new function you wrote to compute the steplength\n",
        "      #raise ValueError('BACKTRACKING LINE SEARCH NOT YET IMPLEMENTED')\n",
        "    elif line_search_type == CONSTANT_STEP_LENGTH: #do a gradient descent with constant step length\n",
        "      step_length = 0.1\n",
        "    else:  \n",
        "      raise ValueError('Line search type unknown. Please check!')\n",
        "    \n",
        "    #implement the gradient descent steps here   \n",
        "    x = np.subtract(x, np.multiply(step_length,np.matmul(D_k,g_x))) #update x = x - step_length*g_x\n",
        "    k += 1 #increment iteration\n",
        "    g_x = evalg(x) #compute gradient at new point\n",
        "\n",
        "    #print('iter:',k, ' x:', x, ' f(x):', evalf(x), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "  return x , k , evalf(x) \n",
        "\n",
        "\n",
        "  #Complete the code   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 7&8."
      ],
      "metadata": {
        "id": "MSL4uYWwkZnP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hoak3jnHkXd"
      },
      "source": [
        "my_start_x = np.array([1.,4000.])\n",
        "my_tol= 1e-12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgu4yasdJEKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a943dac-a3a9-49df-f8be-98166ad999f8"
      },
      "source": [
        "#check gradient descent with exact line search\n",
        "print(\"For Gradient Descent with exact line search:\") \n",
        "optimizer,k,min_value=find_minimizer_gd(my_start_x, my_tol, EXACT_LINE_SEARCH)\n",
        "print(\"Minimizer Value :\",optimizer)\n",
        "print(\"Minimum value : \",min_value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Gradient Descent with exact line search:\n",
            "Minimizer Value : [-7.44595231e-16  4.61544291e-13]\n",
            "Minimum value :  2.1248011077899476e-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0_iOLVoQFYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15fba677-3ddd-4746-cdbb-657046d0f27e"
      },
      "source": [
        "#check gradient descent with backtracking line search \n",
        "alpha_start = 1.\n",
        "rho = 0.5\n",
        "gamma = 0.5\n",
        "print(\"For Gradient Descent with backtracking line search:\") \n",
        "optimizer_bls,k_bls,min_value_bls=find_minimizer_gd(my_start_x, my_tol, BACKTRACKING_LINE_SEARCH,alpha_start,rho,gamma)\n",
        "print(\"Minimizer Value :\",optimizer_bls)\n",
        "print(\"Number of iterations :\",k_bls)\n",
        "print(\"Minimum value : \",min_value_bls)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Gradient Descent with backtracking line search:\n",
            "Minimizer Value : [-4.78532202e-16  4.53575301e-13]\n",
            "Number of iterations : 21985\n",
            "Minimum value :  2.0520584176089396e-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpABILpQxPKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "011866ca-0ff9-44f7-eb0a-e6f505702232"
      },
      "source": [
        "#check gradient descent with scaling and backtracking line search \n",
        "alpha_start = 1.\n",
        "rho = 0.5\n",
        "gamma = 0.5\n",
        "opt_bls_scaling,k_scaling,fun_scaling = find_minimizer_gdscaling(my_start_x, my_tol, BACKTRACKING_LINE_SEARCH,alpha_start,rho,gamma)\n",
        "print(\"For Gradient Descent with backtracking line search and with scaling:\") \n",
        "print(\"Minimizer Value :\",opt_bls_scaling)\n",
        "print(\"Number of iterations :\",k_scaling)\n",
        "print(\"Minimum value : \",fun_scaling)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Gradient Descent with backtracking line search and with scaling:\n",
            "Minimizer Value : [-3.51831747e-16  1.40072073e-14]\n",
            "Number of iterations : 166543\n",
            "Minimum value :  3.621675026196464e-28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation : \\\\\n",
        "Minimum value using Gradient Descent Algorithm with scaling is 3.621675026196464e-28 i.e., $10^{-28}$whereas minimum value using Gradient Descent Algorithm without scaling is 2.0520584176089396e-25 i.e., $10^{-25}$ so we can clearly observe that with scaling we got more accuracy \\\\\n",
        "Number of iterations are more with gradient descent algorithm with scaling "
      ],
      "metadata": {
        "id": "m6KlCOLu91Cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 9."
      ],
      "metadata": {
        "id": "hwShe5EDkfSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha_values=[1.,0.9,0.75,0.6,0.5,0.4,0.25,0.1,0.01]\n",
        "obj_function=[]\n",
        "final_minimizer=[]\n",
        "number_of_iterations=[]\n",
        "print(\"For Gradient Descent with backtracking line search:\")\n",
        "for alpha in alpha_values:\n",
        "  print(\"for alpha = \",alpha)\n",
        "  optimizer_bls,k_bls,min_value_bls=find_minimizer_gd(my_start_x, my_tol, BACKTRACKING_LINE_SEARCH,alpha,rho,gamma)\n",
        "  print(\"   Minimizer Value :\",optimizer_bls,\"   Number of iterations :\",k_bls,\"   Minimum value : \",min_value_bls)\n",
        "  number_of_iterations.append(k_bls)\n",
        "  obj_function.append(min_value_bls)\n",
        "  final_minimizer.append(optimizer_bls)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvZ--tIAkeUI",
        "outputId": "f8fe242f-b759-43b1-f0b0-828392db9026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Gradient Descent with backtracking line search:\n",
            "for alpha =  1.0\n",
            "   Minimizer Value : [-4.78532202e-16  4.53575301e-13]    Number of iterations : 21985    Minimum value :  2.0520584176089396e-25\n",
            "for alpha =  0.9\n",
            "   Minimizer Value : [-5.48799355e-16  4.71515450e-13]    Number of iterations : 15941    Minimum value :  2.2174352131747877e-25\n",
            "for alpha =  0.75\n",
            "   Minimizer Value : [-7.18643891e-16  4.89175378e-13]    Number of iterations : 6750    Minimum value :  2.386610528547938e-25\n",
            "for alpha =  0.6\n",
            "   Minimizer Value : [-6.07554226e-16  4.94036636e-13]    Number of iterations : 6887    Minimum value :  2.43425264283868e-25\n",
            "for alpha =  0.5\n",
            "   Minimizer Value : [-4.78532202e-16  4.53575301e-13]    Number of iterations : 21985    Minimum value :  2.0520584176089396e-25\n",
            "for alpha =  0.4\n",
            "   Minimizer Value : [-7.24091328e-16  4.84454819e-13]    Number of iterations : 11362    Minimum value :  2.3407977615582728e-25\n",
            "for alpha =  0.25\n",
            "   Minimizer Value : [-4.78532202e-16  4.53575301e-13]    Number of iterations : 21985    Minimum value :  2.0520584176089396e-25\n",
            "for alpha =  0.1\n",
            "   Minimizer Value : [-7.24091328e-16  4.84454819e-13]    Number of iterations : 11362    Minimum value :  2.3407977615582728e-25\n",
            "for alpha =  0.01\n",
            "   Minimizer Value : [-5.80852788e-16  4.86459735e-13]    Number of iterations : 5509    Minimum value :  2.3601891237044125e-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha_values=[1.,0.9,0.75,0.6,0.5,0.4,0.25,0.1,0.01]\n",
        "obj_function_scaling=[]\n",
        "final_minimizer_scaling=[]\n",
        "number_of_iterations_scaling=[]\n",
        "print(\"For Gradient Descent with backtracking line search and with scaling:\")\n",
        "for alpha in alpha_values:\n",
        "  print(\"for alpha = \",alpha)\n",
        "  opt_bls_scaling,k_scaling,fun_scaling = find_minimizer_gdscaling(my_start_x, my_tol, BACKTRACKING_LINE_SEARCH,alpha,rho,gamma)\n",
        "  print(\"   Minimizer Value :\",opt_bls_scaling,\"   Number of iterations :\",k_scaling,\"   Minimum value : \",fun_scaling)\n",
        "  obj_function_scaling.append(fun_scaling)\n",
        "  final_minimizer_scaling.append(opt_bls_scaling)\n",
        "  number_of_iterations_scaling.append(k_scaling)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QWWkXCNpQjg",
        "outputId": "ed7c13e3-295b-4646-80ad-9824c009be6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Gradient Descent with backtracking line search and with scaling:\n",
            "for alpha =  1.0\n",
            "   Minimizer Value : [-3.51831747e-16  1.40072073e-14]    Number of iterations : 166543    Minimum value :  3.621675026196464e-28\n",
            "for alpha =  0.9\n",
            "   Minimizer Value : [-3.51880583e-16  1.40092586e-14]    Number of iterations : 184254    Minimum value :  3.6227089793308317e-28\n",
            "for alpha =  0.75\n",
            "   Minimizer Value : [-3.51884177e-16  1.40095324e-14]    Number of iterations : 218081    Minimum value :  3.622817796715079e-28\n",
            "for alpha =  0.6\n",
            "   Minimizer Value : [-3.51873160e-16  1.40090769e-14]    Number of iterations : 139417    Minimum value :  3.6225864420281724e-28\n",
            "for alpha =  0.5\n",
            "   Minimizer Value : [-3.51831747e-16  1.40072073e-14]    Number of iterations : 166543    Minimum value :  3.621675026196464e-28\n",
            "for alpha =  0.4\n",
            "   Minimizer Value : [-3.51878054e-16  1.40093757e-14]    Number of iterations : 205524    Minimum value :  3.6227148828944126e-28\n",
            "for alpha =  0.25\n",
            "   Minimizer Value : [-3.51831747e-16  1.40072073e-14]    Number of iterations : 166543    Minimum value :  3.621675026196464e-28\n",
            "for alpha =  0.1\n",
            "   Minimizer Value : [-3.51878054e-16  1.40093757e-14]    Number of iterations : 205524    Minimum value :  3.6227148828944126e-28\n",
            "for alpha =  0.01\n",
            "   Minimizer Value : [-3.51865929e-16  1.40088957e-14]    Number of iterations : 130859    Minimum value :  3.622465937127626e-28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(alpha_values,number_of_iterations)\n",
        "plt.plot(alpha_values,number_of_iterations_scaling) \n",
        "plt.xlabel('Value of ⍺')\n",
        "plt.ylabel('Number of Iterations')\n",
        "plt.title('Number of Iterations v/s α plot')\n",
        "plt.legend([\"Without Scaling\",\"With Scaling\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "Pc_AJuD9ptp2",
        "outputId": "db45d327-f092-4dc8-b079-6cf9627af38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation : \\\\\n",
        "Number of iterations for Gradient Descent with backtracking line search with scaling are very much as compared to number of iterations without scaling.And we dont see any major change effect on number of iterations w.r.t. change in value of alpha. "
      ],
      "metadata": {
        "id": "cx634_GPA7XY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 10:"
      ],
      "metadata": {
        "id": "-UcKKAUH45eR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rho_values=[0.9,0.8,0.75,0.6,0.5,0.4,0.25,0.1,0.01]\n",
        "alpha_start=1.0\n",
        "gamma=0.5\n",
        "obj_function=[]\n",
        "final_minimizer=[]\n",
        "number_of_iterations=[]\n",
        "print(\"For Gradient Descent with backtracking line search:\")\n",
        "for rho in rho_values:\n",
        "  print(\"for rho = \",rho)\n",
        "  optimizer_bls,k_bls,min_value_bls=find_minimizer_gd(my_start_x, my_tol, BACKTRACKING_LINE_SEARCH,alpha_start,rho,gamma)\n",
        "  print(\"   Minimizer Value :\",optimizer_bls,\"   Number of iterations :\",k_bls,\"   Minimum value : \",min_value_bls)\n",
        "  number_of_iterations.append(k_bls)\n",
        "  obj_function.append(min_value_bls)\n",
        "  final_minimizer.append(optimizer_bls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0Y9iaSBumb1",
        "outputId": "0f2c5d97-6fab-4702-ef45-711453e355a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Gradient Descent with backtracking line search:\n",
            "for rho =  0.9\n",
            "   Minimizer Value : [-6.44686128e-16  4.90962904e-13]    Number of iterations : 127    Minimum value :  2.404019351870065e-25\n",
            "for rho =  0.8\n",
            "   Minimizer Value : [-6.99968590e-16  4.40149178e-13]    Number of iterations : 1471    Minimum value :  1.932338703071826e-25\n",
            "for rho =  0.75\n",
            "   Minimizer Value : [-7.15454842e-16  4.83616543e-13]    Number of iterations : 3135    Minimum value :  2.332687511412074e-25\n",
            "for rho =  0.6\n",
            "   Minimizer Value : [-7.07691748e-16  4.70469643e-13]    Number of iterations : 15834    Minimum value :  2.2076113616544364e-25\n",
            "for rho =  0.5\n",
            "   Minimizer Value : [-4.78532202e-16  4.53575301e-13]    Number of iterations : 21985    Minimum value :  2.0520584176089396e-25\n",
            "for rho =  0.4\n",
            "   Minimizer Value : [-5.16461460e-16  4.67846629e-13]    Number of iterations : 20049    Minimum value :  2.1831406770108246e-25\n",
            "for rho =  0.25\n",
            "   Minimizer Value : [-5.67128954e-16  4.70177132e-13]    Number of iterations : 24570    Minimum value :  2.204823842206756e-25\n",
            "for rho =  0.1\n",
            "   Minimizer Value : [-4.35224428e-16  4.42644725e-13]    Number of iterations : 45435    Minimum value :  1.9544788340231146e-25\n",
            "for rho =  0.01\n",
            "   Minimizer Value : [-6.03891924e-16  4.89972672e-13]    Number of iterations : 17463    Minimum value :  2.394366854291179e-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obj_function_scaling=[]\n",
        "final_minimizer_scaling=[]\n",
        "number_of_iterations_scaling=[]\n",
        "print(\"For Gradient Descent with backtracking line search with scaling:\")\n",
        "for rho in rho_values:\n",
        "  print(\"for rho = \",rho)\n",
        "  opt_bls_scaling,k_scaling,fun_scaling = find_minimizer_gdscaling(my_start_x, my_tol, BACKTRACKING_LINE_SEARCH,alpha_start,rho,gamma)\n",
        "  print(\"   Minimizer Value :\",opt_bls_scaling,\"   Number of iterations :\",k_scaling,\"   Minimum value : \",fun_scaling)\n",
        "  obj_function_scaling.append(fun_scaling)\n",
        "  final_minimizer_scaling.append(opt_bls_scaling)\n",
        "  number_of_iterations_scaling.append(k_scaling)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK4sZ31Q5yJ0",
        "outputId": "3c034748-b7d8-465f-f68f-610a50f73118"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Gradient Descent with backtracking line search with scaling:\n",
            "for rho =  0.9\n",
            "   Minimizer Value : [-3.51776084e-16  1.39972555e-14]    Number of iterations : 121440    Minimum value :  3.6184718200920344e-28\n",
            "for rho =  0.8\n",
            "   Minimizer Value : [-3.51791766e-16  1.40037789e-14]    Number of iterations : 125092    Minimum value :  3.620363360810124e-28\n",
            "for rho =  0.75\n",
            "   Minimizer Value : [-3.51805130e-16  1.40062741e-14]    Number of iterations : 127959    Minimum value :  3.6211607293046916e-28\n",
            "for rho =  0.6\n",
            "   Minimizer Value : [-3.51829291e-16  1.40073153e-14]    Number of iterations : 144172    Minimum value :  3.621679222287128e-28\n",
            "for rho =  0.5\n",
            "   Minimizer Value : [-3.51831747e-16  1.40072073e-14]    Number of iterations : 166543    Minimum value :  3.621675026196464e-28\n",
            "for rho =  0.4\n",
            "   Minimizer Value : [-3.51893226e-16  1.40099350e-14]    Number of iterations : 155961    Minimum value :  3.6230153870288696e-28\n",
            "for rho =  0.25\n",
            "   Minimizer Value : [-3.51883626e-16  1.40095882e-14]    Number of iterations : 168136    Minimum value :  3.622827123351012e-28\n",
            "for rho =  0.1\n",
            "   Minimizer Value : [-3.51892191e-16  1.40099220e-14]    Number of iterations : 410047    Minimum value :  3.6230015823951396e-28\n",
            "for rho =  0.01\n",
            "   Minimizer Value : [-3.51875942e-16  1.40095013e-14]    Number of iterations : 414640    Minimum value :  3.6227272016151954e-28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(rho_values,number_of_iterations)\n",
        "plt.plot(rho_values,number_of_iterations_scaling) \n",
        "plt.xlabel('Rho Values')\n",
        "plt.ylabel('Number of Iterations')\n",
        "plt.title('Number of Iterations v/s Rho Values plot')\n",
        "plt.legend([\"Without Scaling\",\"With Scaling\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hzNun45f6Aab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "6a4a0fd9-e14e-4057-8e35-eae3aa0c6e6a"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation : \\\\\n",
        "Number of iterations for Gradient Descent with backtracking line search with scaling are very much as compared to number of iterations without scaling.For Gradient Descnt with backtracking line search With scaling with increase in rho values number of iterations decreases ,initially we can see a very much change in number of iterations from 0.0 to 0.2 and then it decreases minorly."
      ],
      "metadata": {
        "id": "iXZCCdSXCIzF"
      }
    }
  ]
}